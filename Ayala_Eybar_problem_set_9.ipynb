{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ayala_Eybar_problem_set_9",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZO36oMNy6Ef"
      },
      "source": [
        "## Block 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKAW-Bw1yzlU"
      },
      "source": [
        "# importing evertyhing\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "data = sns.load_dataset('geyser')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QGxdvPOzrPh"
      },
      "source": [
        "## Block 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt1vbNsNtnS_"
      },
      "source": [
        "rdata = data[0:270] # dropping last two rows in order to have 27 per fold\n",
        "def cross_val(dataset, k = 10):\n",
        "  results = [] \n",
        "  fold = list()\n",
        "  perfold = len(dataset) // k # how many per fold (27)\n",
        "  for i in range(k):\n",
        "    fold.append(dataset[i*perfold:(i+1)*perfold])\n",
        "  for i in range(k):\n",
        "    Xtest = fold[i].iloc[0:27,0:1] # only duration column\n",
        "    ytest = fold[i].iloc[0:27,1:2] # only waiting column\n",
        "    n_fold = np.concatenate(np.delete(fold,i,0))\n",
        "    Xtrain = n_fold[:,0:1] \n",
        "    ytrain = n_fold[:,1:2]\n",
        "    model = LinearRegression()\n",
        "    model.fit(Xtrain,ytrain)\n",
        "    results.append(model.score(Xtest,ytest))\n",
        "  return results"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJW2kUnBtEqT"
      },
      "source": [
        "## Block 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI4j0Zh6Swg_",
        "outputId": "afd15cc9-daab-4d3f-c0de-ef195e550e1a"
      },
      "source": [
        "all= cross_val(rdata)\n",
        "a = np.array(all)\n",
        "print('The mean')\n",
        "print(a.mean())\n",
        "print('-------------------------------------')\n",
        "print('The Standard Deviation')\n",
        "print(a.std())"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean\n",
            "0.796407413732283\n",
            "-------------------------------------\n",
            "The Standard Deviation\n",
            "0.06653610198795522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hsf7CWRtOhF"
      },
      "source": [
        "## Block 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjkZpzkBuUL7"
      },
      "source": [
        "The result shows that R^2 scores are actually quite high which means that predictive model between the relationship of duration of an eruption and the duration of the next eruption seems to be a good fit. Also, the fact that the standard deviation was really low means that it doesn't matter in what part we take our data from, the result should stay relativily the same that this predictive model fits the observed data."
      ]
    }
  ]
}